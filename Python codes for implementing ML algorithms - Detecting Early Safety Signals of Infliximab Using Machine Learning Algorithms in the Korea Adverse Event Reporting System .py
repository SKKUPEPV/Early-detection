#!/usr/bin/env python
# coding: utf-8

# ## Generating training dataset

# In[3]:


import pandas as pd
import numpy as np

# Uploading excel files (previously generated by SAS)
data_gold = pd.read_excel('Gold standard.xlsx') #data_gold = data for training and evaluation
data_label_gold = data_gold['Label'] #Assign label data for training and evaluation
data_feature_gold = data_gold.iloc[:,2:35] #Assign feature data for training and evaluation


# In[6]:


# Spliting gold standard dataset into training set and test set.
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(data_feature_gold, data_label_gold, test_size = 0.25, random_state=200)

from imblearn.over_sampling import SMOTE # Import SMOTE function
sm = SMOTE(random_state=0)

# Apply the oversamplig method to training set
x_resampled, y_resampled = sm.fit_resample(x_train, y_train)

print('Distribution of feature/Label data in training set before SMOTE apply: ', x_train.shape, y_train.shape)
print('Distribution of feature/Label data in training set after SMOTE apply:: ', x_resampled.shape, y_resampled.shape)
print('Distribution of feature/Label data in training set before SMOTE apply: \n', pd.Series(y_train).value_counts())
print('Distribution of feature/Label data in training set after SMOTE apply: \n', pd.Series(y_resampled).value_counts())


# In[10]:


from sklearn.metrics import roc_auc_score, roc_curve # Import function for estimating performance
from sklearn.model_selection import GridSearchCV, StratifiedKFold # Import function for cross-validation and hyperparameter tuning

import warnings
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
get_ipython().run_line_magic('matplotlib', 'inline')


# ## Generating signal detection model_XGB

# In[12]:


import xgboost as xgb
from xgboost import XGBClassifier #Import gradient boosting machine

#Training gradient boosting machine algorithm by using training set
xgb = XGBClassifier()

xgb_params_grid = {
         'n_estimators':[500], 'eta':[0.1],
         'max_depth':[10], 'min_child_weight':[6], 'gamma':[0.2], 
         'colsample_bytree':[0.8], 
         'random_state':[111]}

skf_infli = StratifiedKFold(n_splits=5) #5-fold cross validation

xgb= GridSearchCV(xgb, param_grid=xgb_params_grid, scoring="roc_auc", cv=skf_infli, n_jobs = -1, verbose = -1)
xgb.fit(x_resampled, y_resampled)

print("Best performance : {0:.4f}".format(xgb.best_score_))
print("Best parameters: ", xgb.best_params_)


xgb_roc_score = roc_auc_score(y_test, xgb.predict_proba(x_test)[:,1], average='macro')
print('ROC AUC:{0:.4f}'.format(xgb_roc_score)) #Evaluate the performance in test set 

#Tuning the parameter until the performance in the training set is about the same as that in the test set


# ## Detecting safety signals by using XGB

# In[30]:


data_detection = pd.read_excel('Unknown ADRs.xlsx') #data_detection = data for detecting safety signals
data_feature_detection = data_detection.iloc[:,1:34] #Assign feature data for detecting safety signals

preds = xgb.predict_proba(data_feature_detection) #Detecting safety signals by using xgb
preds_df = pd.DataFrame(preds)
signal_probability = preds_df.iloc[:,1:2]
signal_probability.to_excel('Data storage location/safety signals.xlsx') #Export the result of signal detection
Safety_signals = (signal_probability >= optimal threshold).astype('int')
Safety_signals_df = pd.DataFrame(Safety_signals)
Safety_signals_df.to_excel('Data storage location/safety signals.xlsx') #Export the result of signal detection


# ## Generating signal detection model_RF

# In[31]:


from sklearn.ensemble import RandomForestClassifier #Import random forest

#Training gradient random forest algorithm by using training set
rf_clf = RandomForestClassifier()

parameters = {
    'n_estimators':[600],
    'max_depth':[12],'min_samples_split':[3],'min_samples_leaf':[3],
    'random_state':[111]}

skf_infli = StratifiedKFold(n_splits=5) #5-fold cross validation

rf = GridSearchCV(rf_clf, param_grid=parameters, scoring='roc_auc', cv=skf_infli, n_jobs = -1, verbose = -1)
rf.fit(x_resampled,y_resampled)

print("Best performance : {0:.4f}".format(rf.best_score_))
print("Best parameters: ", rf.best_params_)

rf_roc_score = roc_auc_score(y_test, rf.predict_proba(x_test)[:,1], average='macro')
print('ROC AUC:{0:.4f}'.format(rf_roc_score)) #Evaluate the performance in test set 

#Tuning the parameter until the performance in the training set is about the same as that in the test set


# ## Detecting safety signals by using RF

# In[35]:


data_detection = pd.read_excel('Unknown ADRs.xlsx') #data_detection = data for detecting safety signals
data_feature_detection = data_detection.iloc[:,1:34] #Assign feature data for detecting safety signals

preds = rf.predict_proba(data_feature_detection) #Detecting safety signals by using xgb
preds_df = pd.DataFrame(preds)
signal_probability = preds_df.iloc[:,1:2]
signal_probability.to_excel('Data storage location/safety signals.xlsx') #Export the result of signal detection
Safety_signals = (signal_probability >= optimal threshold).astype('int')
Safety_signals_df = pd.DataFrame(Safety_signals)
Safety_signals_df.to_excel('Data storage location/safety signals.xlsx') #Export the result of signal detection
